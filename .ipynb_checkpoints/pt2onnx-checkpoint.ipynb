{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4da79a5-d90b-40b2-bd3d-1bd8762240ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 5e16c95 torch 2.0.1+cu117 CPU\n",
      "\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights='runs/detect/train3/weights/best.pt', img_size=[640, 640], batch_size=1, dynamic=False, dynamic_batch=False, grid=False, end2end=False, max_wh=None, topk_all=100, iou_thres=0.45, conf_thres=0.25, device='cpu', simplify=False, include_nms=False, fp16=False, int8=False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Detect' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# elif isinstance(m, models.yolo.Detect):\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m#     m.forward = m.forward_export  # assign forward (optional)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mexport \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mgrid  \u001b[38;5;66;03m# set Detect() layer grid export\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dry run\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39minclude_nms:\n\u001b[1;32m     71\u001b[0m     model\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39minclude_nms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ultralytics/nn/tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ultralytics/nn/tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ultralytics/nn/tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ultralytics/nn/modules/head.py:55\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m     54\u001b[0m x_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([xi\u001b[38;5;241m.\u001b[39mview(shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x], \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgetpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfjs\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# avoid TF FlexSplitV ops\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     box \u001b[38;5;241m=\u001b[39m x_cat[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_max \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m x_cat[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_max \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m:]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Detect' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "sys.path.append('./')  # to run '$ python *.py' files in subdirectories\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "import models\n",
    "from models.experimental import attempt_load, End2End\n",
    "from utils.activations import Hardswish, SiLU\n",
    "from utils.general import set_logging, check_img_size\n",
    "from utils.torch_utils import select_device\n",
    "from utils.add_nms import RegisterNMS\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Example')\n",
    "    parser.add_argument('--weights', type=str, default='runs/detect/train3/weights/best.pt', help='weights path')\n",
    "    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='image size')  # height, width\n",
    "    parser.add_argument('--batch-size', type=int, default=1, help='batch size')\n",
    "    parser.add_argument('--dynamic', action='store_true', help='dynamic ONNX axes')\n",
    "    parser.add_argument('--dynamic-batch', action='store_true', help='dynamic batch onnx for tensorrt and onnx-runtime')\n",
    "    parser.add_argument('--grid', action='store_true', help='export Detect() layer grid')\n",
    "    parser.add_argument('--end2end', action='store_true', help='export end2end onnx')\n",
    "    parser.add_argument('--max-wh', type=int, default=None, help='None for tensorrt nms, int value for onnx-runtime nms')\n",
    "    parser.add_argument('--topk-all', type=int, default=100, help='topk objects for every images')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.45, help='iou threshold for NMS')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.25, help='conf threshold for NMS')\n",
    "    parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--simplify', action='store_true', help='simplify onnx model')\n",
    "    parser.add_argument('--include-nms', action='store_true', help='export end2end onnx')\n",
    "    parser.add_argument('--fp16', action='store_true', help='CoreML FP16 half-precision export')\n",
    "    parser.add_argument('--int8', action='store_true', help='CoreML INT8 quantization')\n",
    "    opt,unknown = parser.parse_known_args()\n",
    "    # opt = parser.parse_args()\n",
    "    opt.img_size *= 2 if len(opt.img_size) == 1 else 1  # expand\n",
    "    opt.dynamic = opt.dynamic and not opt.end2end\n",
    "    opt.dynamic = False if opt.dynamic_batch else opt.dynamic\n",
    "    print(opt)\n",
    "    set_logging()\n",
    "    t = time.time()\n",
    "\n",
    "    # Load PyTorch model\n",
    "    device = select_device(opt.device)\n",
    "    model = attempt_load(opt.weights, map_location=device)  # load FP32 model\n",
    "    labels = model.names\n",
    "\n",
    "    # Checks\n",
    "    gs = int(max(model.stride))  # grid size (max stride)\n",
    "    opt.img_size = [check_img_size(x, gs) for x in opt.img_size]  # verify img_size are gs-multiples\n",
    "\n",
    "    # Input\n",
    "    img = torch.zeros(opt.batch_size, 3, *opt.img_size).to(device)  # image size(1,3,320,192) iDetection\n",
    "\n",
    "    # Update model\n",
    "    for k, m in model.named_modules():\n",
    "        m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility\n",
    "        if isinstance(m, models.common.Conv):  # assign export-friendly activations\n",
    "            if isinstance(m.act, nn.Hardswish):\n",
    "                m.act = Hardswish()\n",
    "            elif isinstance(m.act, nn.SiLU):\n",
    "                m.act = SiLU()\n",
    "        # elif isinstance(m, models.yolo.Detect):\n",
    "        #     m.forward = m.forward_export  # assign forward (optional)\n",
    "    model.model[-1].export = not opt.grid  # set Detect() layer grid export\n",
    "    y = model(img)  # dry run\n",
    "    if opt.include_nms:\n",
    "        model.model[-1].include_nms = True\n",
    "        y = None\n",
    "\n",
    "    # TorchScript export\n",
    "    try:\n",
    "        print('\\nStarting TorchScript export with torch %s...' % torch.__version__)\n",
    "        f = opt.weights.replace('.pt', '.torchscript.pt')  # filename\n",
    "        ts = torch.jit.trace(model, img, strict=False)\n",
    "        ts.save(f)\n",
    "        print('TorchScript export success, saved as %s' % f)\n",
    "    except Exception as e:\n",
    "        print('TorchScript export failure: %s' % e)\n",
    "\n",
    "    # CoreML export\n",
    "    try:\n",
    "        import coremltools as ct\n",
    "\n",
    "        print('\\nStarting CoreML export with coremltools %s...' % ct.__version__)\n",
    "        # convert model from torchscript and apply pixel scaling as per detect.py\n",
    "        ct_model = ct.convert(ts, inputs=[ct.ImageType('image', shape=img.shape, scale=1 / 255.0, bias=[0, 0, 0])])\n",
    "        bits, mode = (8, 'kmeans_lut') if opt.int8 else (16, 'linear') if opt.fp16 else (32, None)\n",
    "        if bits < 32:\n",
    "            if sys.platform.lower() == 'darwin':  # quantization only supported on macOS\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # suppress numpy==1.20 float warning\n",
    "                    ct_model = ct.models.neural_network.quantization_utils.quantize_weights(ct_model, bits, mode)\n",
    "            else:\n",
    "                print('quantization only supported on macOS, skipping...')\n",
    "\n",
    "        f = opt.weights.replace('.pt', '.mlmodel')  # filename\n",
    "        ct_model.save(f)\n",
    "        print('CoreML export success, saved as %s' % f)\n",
    "    except Exception as e:\n",
    "        print('CoreML export failure: %s' % e)\n",
    "                     \n",
    "    # TorchScript-Lite export\n",
    "    try:\n",
    "        print('\\nStarting TorchScript-Lite export with torch %s...' % torch.__version__)\n",
    "        f = opt.weights.replace('.pt', '.torchscript.ptl')  # filename\n",
    "        tsl = torch.jit.trace(model, img, strict=False)\n",
    "        tsl = optimize_for_mobile(tsl)\n",
    "        tsl._save_for_lite_interpreter(f)\n",
    "        print('TorchScript-Lite export success, saved as %s' % f)\n",
    "    except Exception as e:\n",
    "        print('TorchScript-Lite export failure: %s' % e)\n",
    "\n",
    "    # ONNX export\n",
    "    try:\n",
    "        import onnx\n",
    "\n",
    "        print('\\nStarting ONNX export with onnx %s...' % onnx.__version__)\n",
    "        f = opt.weights.replace('.pt', '.onnx')  # filename\n",
    "        model.eval()\n",
    "        output_names = ['classes', 'boxes'] if y is None else ['output']\n",
    "        dynamic_axes = None\n",
    "        if opt.dynamic:\n",
    "            dynamic_axes = {'images': {0: 'batch', 2: 'height', 3: 'width'},  # size(1,3,640,640)\n",
    "             'output': {0: 'batch', 2: 'y', 3: 'x'}}\n",
    "        if opt.dynamic_batch:\n",
    "            opt.batch_size = 'batch'\n",
    "            dynamic_axes = {\n",
    "                'images': {\n",
    "                    0: 'batch',\n",
    "                }, }\n",
    "            if opt.end2end and opt.max_wh is None:\n",
    "                output_axes = {\n",
    "                    'num_dets': {0: 'batch'},\n",
    "                    'det_boxes': {0: 'batch'},\n",
    "                    'det_scores': {0: 'batch'},\n",
    "                    'det_classes': {0: 'batch'},\n",
    "                }\n",
    "            else:\n",
    "                output_axes = {\n",
    "                    'output': {0: 'batch'},\n",
    "                }\n",
    "            dynamic_axes.update(output_axes)\n",
    "        if opt.grid:\n",
    "            if opt.end2end:\n",
    "                print('\\nStarting export end2end onnx model for %s...' % 'TensorRT' if opt.max_wh is None else 'onnxruntime')\n",
    "                model = End2End(model,opt.topk_all,opt.iou_thres,opt.conf_thres,opt.max_wh,device,len(labels))\n",
    "                if opt.end2end and opt.max_wh is None:\n",
    "                    output_names = ['num_dets', 'det_boxes', 'det_scores', 'det_classes']\n",
    "                    shapes = [opt.batch_size, 1, opt.batch_size, opt.topk_all, 4,\n",
    "                              opt.batch_size, opt.topk_all, opt.batch_size, opt.topk_all]\n",
    "                else:\n",
    "                    output_names = ['output']\n",
    "            else:\n",
    "                model.model[-1].concat = True\n",
    "\n",
    "        torch.onnx.export(model, img, f, verbose=False, opset_version=12, input_names=['images'],\n",
    "                          output_names=output_names,\n",
    "                          dynamic_axes=dynamic_axes)\n",
    "\n",
    "        # Checks\n",
    "        onnx_model = onnx.load(f)  # load onnx model\n",
    "        onnx.checker.check_model(onnx_model)  # check onnx model\n",
    "\n",
    "        if opt.end2end and opt.max_wh is None:\n",
    "            for i in onnx_model.graph.output:\n",
    "                for j in i.type.tensor_type.shape.dim:\n",
    "                    j.dim_param = str(shapes.pop(0))\n",
    "\n",
    "        # print(onnx.helper.printable_graph(onnx_model.graph))  # print a human readable model\n",
    "\n",
    "        # # Metadata\n",
    "        # d = {'stride': int(max(model.stride))}\n",
    "        # for k, v in d.items():\n",
    "        #     meta = onnx_model.metadata_props.add()\n",
    "        #     meta.key, meta.value = k, str(v)\n",
    "        # onnx.save(onnx_model, f)\n",
    "\n",
    "        if opt.simplify:\n",
    "            try:\n",
    "                import onnxsim\n",
    "\n",
    "                print('\\nStarting to simplify ONNX...')\n",
    "                onnx_model, check = onnxsim.simplify(onnx_model)\n",
    "                assert check, 'assert check failed'\n",
    "            except Exception as e:\n",
    "                print(f'Simplifier failure: {e}')\n",
    "\n",
    "        # print(onnx.helper.printable_graph(onnx_model.graph))  # print a human readable model\n",
    "        onnx.save(onnx_model,f)\n",
    "        print('ONNX export success, saved as %s' % f)\n",
    "\n",
    "        if opt.include_nms:\n",
    "            print('Registering NMS plugin for ONNX...')\n",
    "            mo = RegisterNMS(f)\n",
    "            mo.register_nms()\n",
    "            mo.save(f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('ONNX export failure: %s' % e)\n",
    "\n",
    "    # Finish\n",
    "    print('\\nExport complete (%.2fs). Visualize with https://github.com/lutzroeder/netron.' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61fbce-86b5-40c8-a1ab-bc0dd6433fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kamal",
   "language": "python",
   "name": "kamal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
